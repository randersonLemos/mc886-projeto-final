{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf; print('Tensorflow version:',tf.__version__)\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "import sklearn\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Available devices:', tf.config.list_physical_devices())\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1*1024)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4618,
     "status": "ok",
     "timestamp": 1635351012644,
     "user": {
      "displayName": "Alexandre Monteiro Ribeiro",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08485424852861072640"
     },
     "user_tz": 180
    },
    "id": "mOWt1owra73r",
    "outputId": "8d91eda7-8477-4d18-b1ca-1e3d2a4925df"
   },
   "outputs": [],
   "source": [
    "DIRECTORY = 'dataset_plus'\n",
    "IMAGE_SIZE = (224, 224)\n",
    "IMAGE_SHAPE = IMAGE_SIZE + (3,)\n",
    "BATCH_SIZE = 16\n",
    "COLOR_MODE='rgb'\n",
    "\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "      directory=DIRECTORY\n",
    "    , image_size=IMAGE_SIZE\n",
    "    , batch_size=BATCH_SIZE    \n",
    "    , color_mode=COLOR_MODE\n",
    "    , validation_split=0.2\n",
    "    , subset=\"training\"\n",
    "    , seed=123\n",
    ")\n",
    "\n",
    "validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "      directory=DIRECTORY\n",
    "    , image_size=IMAGE_SIZE\n",
    "    , batch_size=BATCH_SIZE\n",
    "    , color_mode=COLOR_MODE\n",
    "    , validation_split=0.2\n",
    "    , subset=\"validation\"\n",
    "    , seed=123\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtyLabels = [0]*8\n",
    "Images = {}\n",
    "for images, labels in train_dataset:\n",
    "    for image, label in zip(images, labels):\n",
    "        label = int(label)\n",
    "        qtyLabels[label] += 1  \n",
    "        if ( label in Images ):\n",
    "            if  ( len(Images[label]) < 20 ):\n",
    "                Images[label].append(image)\n",
    "        else:\n",
    "            Images[label] = []\n",
    "            Images[label].append(image)\n",
    "class_names = train_dataset.class_names\n",
    "print(' '.join( ['{:<12}'.format(el) for el in class_names] ))\n",
    "print(' '.join( ['{:<12}'.format(el) for el in qtyLabels] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "executionInfo": {
     "elapsed": 5568,
     "status": "ok",
     "timestamp": 1635351019650,
     "user": {
      "displayName": "Alexandre Monteiro Ribeiro",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08485424852861072640"
     },
     "user_tz": 180
    },
    "id": "tTFxIdwLdXsN",
    "outputId": "232c3c45-b478-4f23-dbb5-6895eab110ba"
   },
   "outputs": [],
   "source": [
    "for label in Images:\n",
    "    images = Images[label]\n",
    "    class_name = class_names[label]\n",
    "    f, axs = plt.subplots(2, 10, figsize=(25, 4))\n",
    "    axs = axs.reshape(-1)\n",
    "    f.suptitle(class_name.upper())\n",
    "    for i, image in enumerate(images):\n",
    "        ax = plt.subplot(2, 10, i + 1)\n",
    "        axs[i].imshow(image.numpy().astype(\"uint8\"), cmap='gray')\n",
    "        axs[i].axis(\"off\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1635351019651,
     "user": {
      "displayName": "Alexandre Monteiro Ribeiro",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08485424852861072640"
     },
     "user_tz": 180
    },
    "id": "baBxHUBXde13",
    "outputId": "28160fdd-0514-4751-af46-3cda6388140f"
   },
   "outputs": [],
   "source": [
    "validation_dataset_cardinality = tf.data.experimental.cardinality(validation_dataset)\n",
    "test_dataset = validation_dataset.take(validation_dataset_cardinality // 5)\n",
    "\n",
    "print('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))\n",
    "print('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1635351019651,
     "user": {
      "displayName": "Alexandre Monteiro Ribeiro",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08485424852861072640"
     },
     "user_tz": 180
    },
    "id": "JiYDr9cFdi9V"
   },
   "outputs": [],
   "source": [
    "# AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset      = train_dataset.cache().prefetch(buffer_size=BATCH_SIZE)\n",
    "validation_dataset = validation_dataset.cache().prefetch(buffer_size=BATCH_SIZE)\n",
    "test_dataset       = test_dataset.cache().prefetch(buffer_size=BATCH_SIZE)\n",
    "\n",
    "# Use data augmentation\n",
    "ZOOM = (0.0, -0.2)\n",
    "data_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "          tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\")\n",
    "        , tf.keras.layers.experimental.preprocessing.RandomRotation(factor=0.05, fill_mode='nearest')\n",
    "        # , tf.keras.layers.experimental.preprocessing.RandomZoom(height_factor=ZOOM, width_factor=ZOOM)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 543
    },
    "executionInfo": {
     "elapsed": 5216,
     "status": "ok",
     "timestamp": 1635351024863,
     "user": {
      "displayName": "Alexandre Monteiro Ribeiro",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08485424852861072640"
     },
     "user_tz": 180
    },
    "id": "KSsSxdGMdlkp",
    "outputId": "060752f8-b6a8-4de0-a569-dfb0964a194a"
   },
   "outputs": [],
   "source": [
    "for images, labels in train_dataset.take(1):\n",
    "    plt.figure(figsize=(30, 10))\n",
    "    image = images[0]    \n",
    "    for i in range(25):\n",
    "        ax = plt.subplot(5, 5, i + 1)\n",
    "        augmented_image = data_augmentation(tf.expand_dims(image, 0))\n",
    "        plt.imshow(augmented_image[0].numpy() / 255, cmap='gray')\n",
    "        plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1635351024863,
     "user": {
      "displayName": "Alexandre Monteiro Ribeiro",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08485424852861072640"
     },
     "user_tz": 180
    },
    "id": "L8nDiNb_dy0g",
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_SHAPE = image.shape\n",
    "# Carregamento do modelo pré-treinado SEM as camadas densas\n",
    "# (include_top = False)\n",
    "base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "# Descongela camadas pré-treinadas\n",
    "for layer in base_model.layers[:-10]:\n",
    "    layer.trainable = False\n",
    "for layer in base_model.layers[-10:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Insere novas camadas no fim da rede para classificação\n",
    "base_model = tf.keras.Sequential([\n",
    "base_model,\n",
    "tf.keras.layers.GlobalAveragePooling2D(),\n",
    "tf.keras.layers.Dense(8, activation='softmax')\n",
    "])\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=INPUT_SHAPE)\n",
    "x = data_augmentation(inputs)\n",
    "outputs = base_model(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(train_dataset))\n",
    "feature_batch = model(image_batch)\n",
    "print(feature_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CNN output format')\n",
    "print(' '.join('{:^12s}'.format(el) for el in class_names))\n",
    "for row in feature_batch.numpy():\n",
    "   print(' '.join('{:^12.2f}'.format(el) for el in row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataset label format')\n",
    "label_batch.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "base_learning_rate = 0.00001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "loss0, accuracy0 = model.evaluate(validation_dataset)\n",
    "print(\"initial loss: {:.2f}\".format(loss0))\n",
    "print(\"initial accuracy: {:.2f}\".format(accuracy0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 save_freq=10*BATCH_SIZE,\n",
    "                                                 verbose=1)\n",
    "\n",
    "initial_epochs = 50\n",
    "history = model.fit(train_dataset,\n",
    "                    validation_data=validation_dataset,\n",
    "                    epochs=initial_epochs,\n",
    "                    callbacks=[cp_callback]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the learning curves of the training and validation accuracy/loss\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()), 1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0, 3.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels = []\n",
    "Predss = []\n",
    "count = 0\n",
    "for batch, labels in validation_dataset:\n",
    "    logits = model.predict_on_batch(batch)\n",
    "    preds  = np.argmax(logits, axis=1) \n",
    "    Predss += preds.tolist()\n",
    "    Labels += labels.numpy().tolist()\n",
    "    count  += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion matrix')\n",
    "confusion = confusion_matrix(Labels, Predss)\n",
    "print(' '.join('{:<12s}'.format(el) for el in class_names))\n",
    "for row in confusion:\n",
    "    print(' '.join('{:<12d}'.format(el) for el in row))\n",
    "print('===')\n",
    "print('Precision per class')\n",
    "num = [confusion[i,i] for i in range(len(confusion))]\n",
    "den = np.sum(confusion, axis=0)\n",
    "print(' '.join('{:<12s}'.format(el) for el in class_names))\n",
    "print(' '.join('{:<12.2f}'.format(el) for el in num/den))\n",
    "print('---')\n",
    "print('mean precision: {:<12.2f}'.format(np.mean(num/den)))\n",
    "print('===')\n",
    "print('Recall per class')\n",
    "num = [confusion[i,i] for i in range(len(confusion))]\n",
    "den = np.sum(confusion, axis=1)\n",
    "print(' '.join('{:<12s}'.format(el) for el in class_names))\n",
    "print(' '.join('{:<12.2f}'.format(el) for el in num/den))\n",
    "print('---')\n",
    "print('mean recall (balanced accuracy score): {:<12.2f}'.format(np.mean(num/den)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20*0.6, 10*0.6))\n",
    "ConfusionMatrixDisplay.from_predictions(Labels, Predss, normalize=None, display_labels=class_names, xticks_rotation='vertical', values_format='d', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation and prediction\n",
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print('Test accuracy :', accuracy)\n",
    "\n",
    "#Retrieve a batch of images from the test set\n",
    "image_batch, label_batch = test_dataset.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch)\n",
    "print('pred', predictions)\n",
    "\n",
    "\n",
    "# Apply a sigmoid since our model returns logits\n",
    "predicted_class = np.argmax(predictions, axis=-1)\n",
    "\n",
    "print('Predictions:\\n', predicted_class)\n",
    "print('Labels:\\n', label_batch)\n",
    "print('Classes:\\n', class_names)\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(15):\n",
    "    ax = plt.subplot(5, 3, i + 1)\n",
    "    plt.imshow(image_batch[i].astype(\"uint8\"), cmap='gray')\n",
    "    plt.title('P -> {}, E -> {}'.format(class_names[predicted_class[i]], class_names[label_batch[i]]))\n",
    "    plt.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "transfer_learning_v3small.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb",
     "timestamp": 1619802747894
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
